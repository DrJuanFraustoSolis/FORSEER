{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16bf648",
   "metadata": {},
   "source": [
    "# Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse.linalg import svds\n",
    "from datetime import datetime\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX \n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose \n",
    "from sklearn import set_config \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "################################################################################################################\n",
    "physical_cpu = tf.config.list_physical_devices('CPU')\n",
    "print(\"CPU's Disponibles: \" + str(len(physical_cpu)))\n",
    "for cpu in physical_cpu:\n",
    "    print(cpu)\n",
    "    \n",
    "physical_gpu = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPU's Disponibles: \" + str(len(physical_gpu)))\n",
    "for gpu in physical_gpu:\n",
    "    print(gpu)\n",
    "################################################################################################################\n",
    "best_mse = 0\n",
    "best_mape = 0\n",
    "best_smape = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157614a4",
   "metadata": {},
   "source": [
    "# Preprocesar Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "import pandas as pd\n",
    "########Control###########\n",
    "file_name = \"INSTANCIAS/CDMX.csv\"\n",
    "original_seasonal_length= 365\n",
    "seasonal_length = 52 #representa la duración de un periodo en mi serie de tiempo\n",
    "percentage_train = 0.7\n",
    "percentage_train_val = 0.7\n",
    "\n",
    "#Lectura de los datos\n",
    "column_names = [\"Date\", \"Temp\"]\n",
    "dataset_path = file_name\n",
    "raw_dataset = pd.read_csv(dataset_path, names = column_names, na_values = \"?\", comment = \"\\t\", sep=\",\", skipinitialspace = True)\n",
    "dataset = raw_dataset.copy()\n",
    "column_names.remove(\"Date\") \n",
    "dataset[\"Date\"] = dataset.Date \\\n",
    "                             .map(lambda x : datetime.strptime(str(x), \"%d/%m/%Y\"))\n",
    "#reindexación y eliminación de columnas basura\n",
    "dataset.index = dataset.Date\n",
    "dataset.pop(\"Date\")\n",
    "\n",
    "#Interpolar los datos faltantes\n",
    "dataset.interpolate(inplace=True, method = \"time\")\n",
    "#Reducción del ruido\n",
    "data = np.array(dataset)\n",
    "#Proceso de hankelización \n",
    "ancho_hankel = original_seasonal_length   #Un periodo estacional\n",
    "matrix = []\n",
    "index = 0\n",
    "for i in range(len(data)-ancho_hankel):\n",
    "    fila = data[index:index+ancho_hankel]\n",
    "    matrix.append(fila)\n",
    "    index +=1\n",
    "matrix = np.array(matrix)\n",
    "matrix = np.reshape(matrix,(matrix.shape[0],matrix.shape[1]))\n",
    "#Descomposición en valores singulares\n",
    "num_components = 20\n",
    "u, s, v = svds(matrix, k = num_components)\n",
    "sdiag = np.diag(s)\n",
    "partial = np.matmul(u, sdiag)\n",
    "reconstruida = np.matmul(partial,v)\n",
    "#Deshankelización\n",
    "nueva_serie = []\n",
    "state = True\n",
    "for i in reconstruida:\n",
    "    if state:\n",
    "        for j in i:\n",
    "            nueva_serie.append(j)\n",
    "        state = False\n",
    "    else:\n",
    "        nueva_serie.append(i[len(i)-1])\n",
    "nueva_serie.append(i[len(i)-1])\n",
    "#print(nueva_serie)\n",
    "#Normalización\n",
    "nueva_serie = ((nueva_serie-min(nueva_serie))/(max(nueva_serie)-min(nueva_serie)))\n",
    "#Reindexado\n",
    "array = np.array(nueva_serie)\n",
    "index_values = dataset.index\n",
    "#array = array[:len(index_values)]\n",
    "dataset = pd.DataFrame(data = array, \n",
    "                      index = index_values,\n",
    "                      columns = column_names)\n",
    "logic = {'Temp'  : 'mean'}\n",
    "dataset = dataset.resample('W').apply(logic)\n",
    "dataset.index -= to_offset(\"6D\")\n",
    "#Interpolar los datos faltantes\n",
    "dataset.interpolate(inplace=True, method = \"time\")\n",
    "\n",
    "decompose = seasonal_decompose(dataset, model = \"add\", extrapolate_trend='freq',  two_sided=True, period = seasonal_length)\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------\")\n",
    "print(decompose.trend)\n",
    "np.savetxt('datos.txt', decompose.trend)\n",
    "print(\"-------------------------------------------------------------------------------------------------------------------\")\n",
    "### La serie ya esta filtrada, ahora se divide en 3(train, validation, test)\n",
    "percentage_train_split = int(len(dataset)*percentage_train)\n",
    "test = dataset[percentage_train_split:]\n",
    "test.index = [pd.Timestamp(d) for d in test.index]\n",
    "train_temp = dataset[:percentage_train_split]\n",
    "train_temp.index = [pd.Timestamp(d) for d in train_temp.index]\n",
    "percentage_val_split = int(len(train_temp)*percentage_train_val)\n",
    "validation = train_temp[percentage_val_split:]\n",
    "validation.index = [pd.Timestamp(d) for d in validation.index]\n",
    "train = dataset[:percentage_val_split]\n",
    "train.index = [pd.Timestamp(d) for d in train.index]\n",
    "#Descompuestos los 3 sets, se debe descomponer cada uno de ellos en tendencia, estacionalidad y ruido\n",
    "decompose_result_train = seasonal_decompose(train,model=\"add\", extrapolate_trend='freq',  two_sided=True, period = seasonal_length)\n",
    "decompose_result_val = seasonal_decompose(validation,model=\"add\", extrapolate_trend='freq',  two_sided=True, period = seasonal_length)\n",
    "decompose_result_test = seasonal_decompose(test,model=\"add\", extrapolate_trend='freq',  two_sided=True, period = seasonal_length)\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(decompose_result_val.observed, label='Observado')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Serie Temporal Observada')\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(decompose_result_val.trend, label='Tendencia')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Tendencia')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(decompose_result_val.seasonal, label='Estacionalidad')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Estacionalidad')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(decompose_result_val.resid, label='Residuos')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Residuos')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true) / ((np.abs(y_true) + np.abs(y_pred)) / 2))\n",
    "\n",
    "\n",
    "\n",
    "##3 bloques descompuestos en 3 componentes\n",
    "train_trend = decompose_result_train.trend\n",
    "train_season =decompose_result_train.seasonal\n",
    "train_resid = decompose_result_train.resid\n",
    "val_trend = decompose_result_val.trend\n",
    "val_season =decompose_result_val.seasonal\n",
    "val_resid = decompose_result_val.resid\n",
    "test_trend = decompose_result_test.trend\n",
    "test_season =decompose_result_test.seasonal\n",
    "test_resid = decompose_result_test.resid\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cadb3b",
   "metadata": {},
   "source": [
    "# Regresores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494330f",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603db418",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_trend_model = None\n",
    "rf_season_model = None\n",
    "rf_resid_model = None\n",
    "\n",
    "def randomForestTrain():\n",
    "    global rf_trend_model, rf_season_model, rf_resid_model\n",
    "    global train_trend, train_season, train_resid\n",
    "    train_tren = pd.DataFrame(train_trend).to_numpy()\n",
    "    train_seaso = pd.DataFrame(train_season).to_numpy()\n",
    "    train_resi = pd.DataFrame(train_resid).to_numpy()\n",
    "    #########################################################################################\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_tren)-ancho_hankel):\n",
    "        fila = train_tren[index:index+ancho_hankel]\n",
    "        rf_trend_char.append(fila)\n",
    "        index +=1\n",
    "    rf_trend_char = np.array(rf_trend_char)\n",
    "    rf_trend_char = np.reshape(rf_trend_char,(rf_trend_char.shape[0],rf_trend_char.shape[1]))\n",
    "    rf_trend = np.array(train_tren).reshape(-1,1)\n",
    "    rf_trend = np.delete(rf_trend, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_seaso)-ancho_hankel):\n",
    "        fila = train_seaso[index:index+ancho_hankel]\n",
    "        rf_season_char.append(fila)\n",
    "        index +=1\n",
    "    rf_season_char = np.array(rf_season_char)\n",
    "    rf_season_char = np.reshape(rf_season_char,(rf_season_char.shape[0],rf_season_char.shape[1]))\n",
    "    rf_season = np.array(train_seaso).reshape(-1,1)\n",
    "    rf_season = np.delete(rf_season, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_resi)-ancho_hankel):\n",
    "        fila = train_resi[index:index+ancho_hankel]\n",
    "        rf_resid_char.append(fila)\n",
    "        index +=1\n",
    "    rf_resid_char = np.array(rf_resid_char)\n",
    "    rf_resid_char = np.reshape(rf_resid_char,(rf_resid_char.shape[0],rf_resid_char.shape[1]))\n",
    "    rf_resid = np.array(train_resi).reshape(-1,1)\n",
    "    rf_resid = np.delete(rf_resid, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    set_config(print_changed_only=False) \n",
    "    \n",
    "    if True:\n",
    "        rf_trend_model = RandomForestRegressor(bootstrap=True, \n",
    "                                               criterion='squared_error',  # squared_error para una tendencia suave\n",
    "                                               max_depth=None, \n",
    "                                               max_features=1,  # 'auto' suele funcionar bien para muchos casos\n",
    "                                               n_estimators=10000,  # empezar con un número menor de estimadores\n",
    "                                               min_samples_split=2,\n",
    "                                               min_samples_leaf=1,\n",
    "                                               n_jobs=-1, \n",
    "                                               random_state=42,  # Para reproducibilidad\n",
    "                                               verbose=0)\n",
    "        rf_season_model = RandomForestRegressor(bootstrap=True, \n",
    "                                                criterion='squared_error', \n",
    "                                                max_depth=None, \n",
    "                                                max_features=1,  \n",
    "                                                n_estimators=10000,  \n",
    "                                                min_samples_split=2,\n",
    "                                                min_samples_leaf=1,\n",
    "                                                n_jobs=-1, \n",
    "                                                random_state=42,  \n",
    "                                                verbose=0)\n",
    "        rf_resid_model = RandomForestRegressor(bootstrap=True, \n",
    "                                               criterion='squared_error', \n",
    "                                               max_depth=None, \n",
    "                                               max_features=1,  \n",
    "                                               n_estimators=10000,  \n",
    "                                               min_samples_split=2,\n",
    "                                               min_samples_leaf=1,\n",
    "                                               n_jobs=-1, \n",
    "                                               random_state=42,  \n",
    "                                               verbose=0)\n",
    "\n",
    "    rf_trend_model = rf_trend_model.fit(rf_trend_char, rf_trend.ravel())\n",
    "    rf_season_model = rf_season_model.fit(rf_season_char, rf_season.ravel()) \n",
    "    rf_resid_model = rf_resid_model.fit(rf_resid_char, rf_resid.ravel())\n",
    "    \n",
    "    global val_trend, val_season, val_resid\n",
    "    val_tren = pd.DataFrame(val_trend).to_numpy()\n",
    "    val_seaso = pd.DataFrame(val_season).to_numpy()\n",
    "    val_resi = pd.DataFrame(val_resid).to_numpy()\n",
    "    #########################################################################################\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_tren)-ancho_hankel):\n",
    "        fila = val_tren[index:index+ancho_hankel]\n",
    "        rf_trend_char.append(fila)\n",
    "        index +=1\n",
    "    rf_trend_char = np.array(rf_trend_char)\n",
    "    rf_trend_char = np.reshape(rf_trend_char,(rf_trend_char.shape[0],rf_trend_char.shape[1]))\n",
    "    rf_trend = np.array(val_tren).reshape(-1,1)\n",
    "    rf_trend = np.delete(rf_trend, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_seaso)-ancho_hankel):\n",
    "        fila = val_seaso[index:index+ancho_hankel]\n",
    "        rf_season_char.append(fila)\n",
    "        index +=1\n",
    "    rf_season_char = np.array(rf_season_char)\n",
    "    rf_season_char = np.reshape(rf_season_char,(rf_season_char.shape[0],rf_season_char.shape[1]))\n",
    "    rf_season = np.array(val_seaso).reshape(-1,1)\n",
    "    rf_season = np.delete(rf_season, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_resi)-ancho_hankel):\n",
    "        fila = val_resi[index:index+ancho_hankel]\n",
    "        rf_resid_char.append(fila)\n",
    "        index +=1\n",
    "    rf_resid_char = np.array(rf_resid_char)\n",
    "    rf_resid_char = np.reshape(rf_resid_char,(rf_resid_char.shape[0],rf_resid_char.shape[1]))\n",
    "    rf_resid = np.array(val_resi).reshape(-1,1)\n",
    "    rf_resid = np.delete(rf_resid, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #Entrenados los modelos se evalua su desempeño con el conjunto de validación\n",
    "\n",
    "    rf_trend_predict = rf_trend_model.predict(rf_trend_char)\n",
    "    rf_season_predict = rf_season_model.predict(rf_season_char)\n",
    "    rf_resid_predict = rf_resid_model.predict(rf_resid_char)\n",
    "    print(\"====================Random Forest Values====================\")\n",
    "    #global mse_r\n",
    "    smape_rf_trend = smape(rf_trend, rf_trend_predict)\n",
    "    smape_rf_season = smape(rf_season, rf_season_predict)\n",
    "    smape_rf_resid = smape(rf_resid, rf_resid_predict)\n",
    "    mse_rf_trend = mean_squared_error(rf_trend, rf_trend_predict)\n",
    "    mape_rf_trend = mean_absolute_percentage_error(rf_trend, rf_trend_predict)\n",
    "    mse_rf_season = mean_squared_error(rf_season, rf_season_predict)\n",
    "    mape_rf_season = mean_absolute_percentage_error(rf_season, rf_season_predict)\n",
    "    mse_rf_resid = mean_squared_error(rf_resid, rf_resid_predict)\n",
    "    mape_rf_resid = mean_absolute_percentage_error(rf_resid, rf_resid_predict)\n",
    "    print(\"trend rf\\t  MSE: \" + str(mse_rf_trend) + \"\\t MAPE: \"+ str(mape_rf_trend) + \"\\t sMAPE: \"+ str(smape_rf_trend) )\n",
    "    print(\"season rf\\t  MSE: \" + str(mse_rf_season) + \"\\t MAPE: \"+ str(mape_rf_season)+ \"\\t sMAPE: \"+ str(smape_rf_season))\n",
    "    print(\"resid rf\\t  MSE: \" + str(mse_rf_resid) + \"\\t MAPE: \"+ str(mape_rf_resid)+ \"\\t sMAPE: \"+ str(smape_rf_resid))\n",
    "    prueba = rf_trend_predict + rf_season_predict + rf_resid_predict\n",
    "    prueba_original = rf_trend + rf_season + rf_resid\n",
    "    print(\"Mape gral: \", mean_absolute_percentage_error(prueba, prueba_original))\n",
    "    print(\"sMape gral: \", smape(prueba, prueba_original))\n",
    "    print(\"MSE gral: \", mean_absolute_percentage_error(prueba, prueba_original))\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.plot(prueba, color = \"gray\")\n",
    "    plt.plot(prueba_original, color = \"green\")\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(18,8),\n",
    "                             sharex=True)\n",
    "    f.suptitle(\"Decomposition-Based Random Forest Forecasting\")\n",
    "    \n",
    "    ax1.set_title('Trend component')\n",
    "    ax1.plot(rf_trend, color = \"green\", label=\"observed\")\n",
    "    ax1.plot(rf_trend_predict, color = \"gray\", label=\"estimated\")\n",
    "    ax1.set(ylabel=\"Temperature trend\")\n",
    "    ax1.set(xlabel=\"Periods\")\n",
    "    f.legend()\n",
    "    \n",
    "    ax2.set_title('Seasonal component')\n",
    "    ax2.plot(rf_season, color = \"green\", label=\"observed\")\n",
    "    ax2.plot(rf_season_predict, color = \"gray\", label=\"estimated\")\n",
    "    ax2.set(ylabel=\"Temperature seasonal\")\n",
    "    ax2.set(xlabel=\"Periods\")\n",
    "    \n",
    "    ax3.set_title('Noise component')\n",
    "    ax3.plot(rf_resid, color = \"green\", label=\"observed\")\n",
    "    ax3.plot(rf_resid_predict, color = \"gray\", label=\"estimated\")\n",
    "    ax3.set(xlabel=\"Periods\")\n",
    "    ax3.set(ylabel=\"Noise\")\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"====================Done Random Forest====================\\n\")\n",
    "    return mape_rf_trend, mape_rf_season, mape_rf_resid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8993bdb2",
   "metadata": {},
   "source": [
    "#  LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9508c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_trend = None\n",
    "lstm_model_season = None\n",
    "lstm_model_resid = None\n",
    "\n",
    "def lstmTrain():\n",
    "    global train_trend, train_season, train_resid\n",
    "    train_tren = pd.DataFrame(train_trend).to_numpy()\n",
    "    train_seaso = pd.DataFrame(train_season).to_numpy()\n",
    "    train_resi = pd.DataFrame(train_resid).to_numpy()\n",
    "    #########################################################################################\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    lstm_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_tren)-ancho_hankel):\n",
    "        fila = train_tren[index:index+ancho_hankel]\n",
    "        lstm_trend_char.append(fila)\n",
    "        index +=1\n",
    "    lstm_trend_char = np.array(lstm_trend_char)\n",
    "    lstm_trend_char = np.reshape(lstm_trend_char,(lstm_trend_char.shape[0],lstm_trend_char.shape[1]))\n",
    "    lstm_trend = np.array(train_tren).reshape(-1,1)\n",
    "    lstm_trend = np.delete(lstm_trend, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    lstm_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_seaso)-ancho_hankel):\n",
    "        fila = train_seaso[index:index+ancho_hankel]\n",
    "        lstm_season_char.append(fila)\n",
    "        index +=1\n",
    "    lstm_season_char = np.array(lstm_season_char)\n",
    "    lstm_season_char = np.reshape(lstm_season_char,(lstm_season_char.shape[0],lstm_season_char.shape[1]))\n",
    "    lstm_season = np.array(train_seaso).reshape(-1,1)\n",
    "    lstm_season = np.delete(lstm_season, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    lstm_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_resi)-ancho_hankel):\n",
    "        fila = train_resi[index:index+ancho_hankel]\n",
    "        lstm_resid_char.append(fila)\n",
    "        index +=1\n",
    "    lstm_resid_char = np.array(lstm_resid_char)\n",
    "    lstm_resid_char = np.reshape(lstm_resid_char,(lstm_resid_char.shape[0],lstm_resid_char.shape[1]))\n",
    "    lstm_resid = np.array(train_resi).reshape(-1,1)\n",
    "    lstm_resid = np.delete(lstm_resid, range(1,ancho_hankel+1))\n",
    "    ############################################################################################################\n",
    "    ######################################################################################################################\n",
    "    global lstm_model_trend, lstm_model_season, lstm_model_resid\n",
    "    ############################################################################################################\n",
    "    lstm_model_trend = Sequential()\n",
    "    lstm_model_trend.add(LSTM(12, input_shape=(12,1), return_sequences = False))\n",
    "    #lstm_model_trend.add(LSTM (15, return_sequences = False))\n",
    "    #lstm_model_trend.add(LSTM (15, return_sequences = True))\n",
    "    #lstm_model_trend.add (LSTM (15, return_sequences = False)) #En esta capa se estable que el retorno de secuencias es false ya que pasa la información directamente a la red MLP  \n",
    "    lstm_model_trend.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_trend.add(Dense(1, activation = \"linear\"))\n",
    "    lstm_model_trend.compile(loss=\"mape\", optimizer=Adam(learning_rate=0.001), metrics=[\"mape\",\"mse\"])\n",
    "    #lstm_model_trend.summary()\n",
    "    ############################################################################################################\n",
    "    lstm_model_season = Sequential()\n",
    "    lstm_model_season.add(LSTM(24, input_shape=(12,1), return_sequences = False))\n",
    "    #lstm_model_season.add(LSTM (20, return_sequences = True))\n",
    "    #lstm_model_season.add(LSTM (20, return_sequences = False))\n",
    "    #lstm_model_season.add(LSTM (15, return_sequences = True))\n",
    "    #lstm_model_season.add (LSTM (15, return_sequences = False)) #En esta capa se estable que el retorno de secuencias es false ya que pasa la información directamente a la red MLP  \n",
    "    #lstm_model_season.add(Dense(10, activation = \"tanh\"))\n",
    "    lstm_model_season.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_season.add(Dropout(0.2))\n",
    "    lstm_model_season.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_season.add(Dropout(0.2))\n",
    "    lstm_model_season.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_season.add(Dropout(0.2))\n",
    "    lstm_model_season.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_season.add(Dropout(0.2))\n",
    "    lstm_model_season.add(Dense(1, activation = \"linear\"))\n",
    "    lstm_model_season.compile(loss=\"mape\", optimizer=Adam(learning_rate=0.001), metrics=[\"mape\",\"mse\"])\n",
    "    #lstm_model_season.summary()\n",
    "    ############################################################################################################\n",
    "    lstm_model_resid = Sequential()\n",
    "    lstm_model_resid.add(LSTM(36, input_shape=(12,1), return_sequences = False))\n",
    "    #lstm_model_resid.add(LSTM (15, return_sequences = True))\n",
    "    #lstm_model_resid.add(LSTM (15, return_sequences = True))\n",
    "    #lstm_model_resid.add (LSTM (15, return_sequences = False)) #En esta capa se estable que el retorno de secuencias es false ya que pasa la información directamente a la red MLP  \n",
    "    #lstm_model_resid.add(Dense(10, activation = \"tanh\"))\n",
    "    lstm_model_resid.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_resid.add(Dropout(0.2))\n",
    "    lstm_model_resid.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_resid.add(Dropout(0.2))\n",
    "    lstm_model_resid.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_resid.add(Dropout(0.2))\n",
    "    lstm_model_resid.add(Dense(100, activation = \"tanh\"))\n",
    "    lstm_model_resid.add(Dropout(0.2))\n",
    "    lstm_model_resid.add(Dense(1, activation = \"linear\"))\n",
    "    lstm_model_resid.compile(loss=\"mse\", optimizer=RMSprop(learning_rate=0.001), metrics=[\"mape\",\"mse\"])\n",
    "    #lstm_model_resid.summary()\n",
    "    ############################################################################################################\n",
    "         #VALIDATION\n",
    "    #########################################################################################\n",
    "    global val_trend, val_season, val_resid\n",
    "    val_tren = pd.DataFrame(val_trend).to_numpy()\n",
    "    val_seaso = pd.DataFrame(val_season).to_numpy()\n",
    "    val_resi = pd.DataFrame(val_resid).to_numpy()\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    lstmv_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_tren)-ancho_hankel):\n",
    "        fila = val_tren[index:index+ancho_hankel]\n",
    "        lstmv_trend_char.append(fila)\n",
    "        index +=1\n",
    "    lstmv_trend_char = np.array(lstmv_trend_char)\n",
    "    lstmv_trend_char = np.reshape(lstmv_trend_char,(lstmv_trend_char.shape[0],lstmv_trend_char.shape[1]))\n",
    "    lstmv_trend = np.array(val_tren).reshape(-1,1)\n",
    "    lstmv_trend = np.delete(lstmv_trend, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    lstmv_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_seaso)-ancho_hankel):\n",
    "        fila = val_seaso[index:index+ancho_hankel]\n",
    "        lstmv_season_char.append(fila)\n",
    "        index +=1\n",
    "    lstmv_season_char = np.array(lstmv_season_char)\n",
    "    lstmv_season_char = np.reshape(lstmv_season_char,(lstmv_season_char.shape[0],lstmv_season_char.shape[1]))\n",
    "    lstmv_season = np.array(val_seaso).reshape(-1,1)\n",
    "    lstmv_season = np.delete(lstmv_season, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    lstmv_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_resi)-ancho_hankel):\n",
    "        fila = val_resi[index:index+ancho_hankel]\n",
    "        lstmv_resid_char.append(fila)\n",
    "        index +=1\n",
    "    lstmv_resid_char = np.array(lstmv_resid_char)\n",
    "    lstmv_resid_char = np.reshape(lstmv_resid_char,(lstmv_resid_char.shape[0],lstmv_resid_char.shape[1]))\n",
    "    lstmv_resid = np.array(val_resi).reshape(-1,1)\n",
    "    lstmv_resid = np.delete(lstmv_resid, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #############################################################################################################\n",
    "    callback=EarlyStopping(monitor='val_loss', patience=35),\n",
    "    lstm_model_trend.fit(lstm_trend_char, lstm_trend.ravel(),validation_data=(lstmv_trend_char, lstmv_trend.ravel()),shuffle=True, epochs=500,callbacks=[callback], batch_size=10, verbose=0,use_multiprocessing=True)\n",
    "    lstm_model_season.fit(lstm_season_char, lstm_season.ravel(),validation_data=(lstmv_season_char, lstmv_season.ravel()), shuffle=True, epochs=500,callbacks=[callback], batch_size=10, verbose=0,use_multiprocessing=True)\n",
    "    lstm_model_resid.fit(lstm_resid_char, lstm_resid.ravel(),validation_data=(lstmv_resid_char, lstmv_resid.ravel()),shuffle=True, epochs=500,callbacks=[callback], batch_size=5, verbose=0,use_multiprocessing=True)\n",
    "    \n",
    "    trendPredict = lstm_model_trend.predict(lstmv_trend_char, verbose = 0)\n",
    "    seasonPredict = lstm_model_season.predict(lstmv_season_char, verbose = 0) \n",
    "    residPredict = lstm_model_resid.predict(lstmv_resid_char, verbose = 0) \n",
    "    \n",
    "    prueba = trendPredict + seasonPredict + residPredict\n",
    "    prueba_original = lstmv_trend.ravel()+lstmv_season.ravel()+lstmv_resid.ravel()\n",
    "    mse_rf_trend = mean_squared_error(prueba, prueba_original)\n",
    "    mape_rf_trend = mean_absolute_percentage_error(prueba, prueba_original)\n",
    "    #print(\" Validation values\\t  MSE: \" + str(mse_rf_trend) + \"\\t MAPE: \"+ str(mape_rf_trend))\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    print(\"====================LSTM Values====================\")\n",
    "    #global mse_rfr\n",
    "    smape_lstm_trend = smape(lstmv_trend, trendPredict)\n",
    "    smape_lstm_season = smape(lstmv_season, seasonPredict)\n",
    "    smape_lstm_resid = smape(lstmv_resid, residPredict)\n",
    "    mse_lstm_trend = mean_squared_error(lstmv_trend, trendPredict)\n",
    "    mape_lstm_trend = mean_absolute_percentage_error(lstmv_trend, trendPredict)\n",
    "    mse_lstm_season = mean_squared_error(lstmv_season, seasonPredict)\n",
    "    mape_lstm_season = mean_absolute_percentage_error(lstmv_season, seasonPredict)\n",
    "    mse_lstm_resid = mean_squared_error(lstmv_resid, residPredict)\n",
    "    mape_lstm_resid = mean_absolute_percentage_error(lstmv_resid, residPredict)\n",
    "    print(\"trend lstm\\t  MSE: \" + str(mse_lstm_trend) + \"\\t MAPE: \"+ str(mape_lstm_trend) + \"\\t sMAPE: \"+ str(smape_lstm_trend))\n",
    "    print(\"season lstm\\t  MSE: \" + str(mse_lstm_season) + \"\\t MAPE: \"+ str(mape_lstm_season) + \"\\t sMAPE: \"+ str(smape_lstm_season))\n",
    "    print(\"resid lstm\\t  MSE: \" + str(mse_lstm_resid) + \"\\t MAPE: \"+ str(mape_lstm_resid) + \"\\t sMAPE: \"+ str(smape_lstm_resid))\n",
    "    prueba = trendPredict + seasonPredict + residPredict \n",
    "    prueba_original = lstmv_trend.ravel()+lstmv_season.ravel()+lstmv_resid.ravel()\n",
    "    print(\"Mape gral: \", mean_absolute_percentage_error(prueba, prueba_original))\n",
    "    print(\"sMape gral: \", smape(prueba, prueba_original))\n",
    "    print(\"Mse gral: \", mean_squared_error(prueba, prueba_original))\n",
    "    print(\"====================Done LSTM====================\\n\")\n",
    "    return mape_lstm_trend, mape_lstm_season, mape_lstm_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81eeed",
   "metadata": {},
   "source": [
    "## SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_trend_model = None\n",
    "svr_season_model = None\n",
    "svr_resid_model = None\n",
    "\n",
    "def SVRTrain():\n",
    "    global svr_trend_model, svr_season_model, svr_resid_model\n",
    "    svr_trend_model = None\n",
    "    svr_season_model = None\n",
    "    svr_resid_model = None\n",
    "    \n",
    "    \n",
    "    global train_trend, train_season, train_resid\n",
    "    train_tren = pd.DataFrame(train_trend).to_numpy()\n",
    "    train_seaso = pd.DataFrame(train_season).to_numpy()\n",
    "    train_resi = pd.DataFrame(train_resid).to_numpy()\n",
    "    #########################################################################################\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_tren)-ancho_hankel):\n",
    "        fila = train_tren[index:index+ancho_hankel]\n",
    "        rf_trend_char.append(fila)\n",
    "        index +=1\n",
    "    rf_trend_char = np.array(rf_trend_char)\n",
    "    rf_trend_char = np.reshape(rf_trend_char,(rf_trend_char.shape[0],rf_trend_char.shape[1]))\n",
    "    rf_trend = np.array(train_tren).reshape(-1,1)\n",
    "    rf_trend = np.delete(rf_trend, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_seaso)-ancho_hankel):\n",
    "        fila = train_seaso[index:index+ancho_hankel]\n",
    "        rf_season_char.append(fila)\n",
    "        index +=1\n",
    "    rf_season_char = np.array(rf_season_char)\n",
    "    rf_season_char = np.reshape(rf_season_char,(rf_season_char.shape[0],rf_season_char.shape[1]))\n",
    "    rf_season = np.array(train_seaso).reshape(-1,1)\n",
    "    rf_season = np.delete(rf_season, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(train_resi)-ancho_hankel):\n",
    "        fila = train_resi[index:index+ancho_hankel]\n",
    "        rf_resid_char.append(fila)\n",
    "        index +=1\n",
    "    rf_resid_char = np.array(rf_resid_char)\n",
    "    rf_resid_char = np.reshape(rf_resid_char,(rf_resid_char.shape[0],rf_resid_char.shape[1]))\n",
    "    rf_resid = np.array(train_resi).reshape(-1,1)\n",
    "    rf_resid = np.delete(rf_resid, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    #Seleciona los parametros dependiendo de la instancia\n",
    "    if True:\n",
    "        svr_trend_model = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "        svr_season_model = SVR(kernel='poly', C=1.0, degree=2, epsilon=0.1, gamma='scale', verbose=0)\n",
    "        svr_resid_model = SVR(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale', verbose=0)  \n",
    "        \n",
    "    svr_trend_model.fit(rf_trend_char, rf_trend.ravel())\n",
    "    svr_season_model.fit(rf_season_char, rf_season.ravel())\n",
    "    svr_resid_model.fit(rf_resid_char, rf_resid.ravel())\n",
    "    global val_trend, val_season, val_resid\n",
    "    val_tren = pd.DataFrame(val_trend).to_numpy()\n",
    "    val_seaso = pd.DataFrame(val_season).to_numpy()\n",
    "    val_resi = pd.DataFrame(val_resid).to_numpy()\n",
    "    #########################################################################################\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_tren)-ancho_hankel):\n",
    "        fila = val_tren[index:index+ancho_hankel]\n",
    "        rf_trend_char.append(fila)\n",
    "        index +=1\n",
    "    rf_trend_char = np.array(rf_trend_char)\n",
    "    rf_trend_char = np.reshape(rf_trend_char,(rf_trend_char.shape[0],rf_trend_char.shape[1]))\n",
    "    rf_trend = np.array(val_tren).reshape(-1,1)\n",
    "    rf_trend = np.delete(rf_trend, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_seaso)-ancho_hankel):\n",
    "        fila = val_seaso[index:index+ancho_hankel]\n",
    "        rf_season_char.append(fila)\n",
    "        index +=1\n",
    "    rf_season_char = np.array(rf_season_char)\n",
    "    rf_season_char = np.reshape(rf_season_char,(rf_season_char.shape[0],rf_season_char.shape[1]))\n",
    "    rf_season = np.array(val_seaso).reshape(-1,1)\n",
    "    rf_season = np.delete(rf_season, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_resi)-ancho_hankel):\n",
    "        fila = val_resi[index:index+ancho_hankel]\n",
    "        rf_resid_char.append(fila)\n",
    "        index +=1\n",
    "    rf_resid_char = np.array(rf_resid_char)\n",
    "    rf_resid_char = np.reshape(rf_resid_char,(rf_resid_char.shape[0],rf_resid_char.shape[1]))\n",
    "    rf_resid = np.array(val_resi).reshape(-1,1)\n",
    "    rf_resid = np.delete(rf_resid, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    print(\"====================SVR Values====================\")\n",
    "    svr_trend_predict = svr_trend_model.predict(rf_trend_char)\n",
    "    svr_season_predict = svr_season_model.predict(rf_season_char)\n",
    "    svr_resid_predict = svr_resid_model.predict(rf_resid_char)\n",
    "    #global mse_svr\n",
    "    smape_svr_trend = smape(rf_trend, svr_trend_predict)\n",
    "    smape_svr_season = smape(rf_season, svr_season_predict)\n",
    "    smape_svr_resid = smape(rf_resid, svr_resid_predict)\n",
    "    mse_svr_trend = mean_squared_error(rf_trend, svr_trend_predict)\n",
    "    mape_svr_trend = mean_absolute_percentage_error(rf_trend, svr_trend_predict)\n",
    "    mse_svr_season = mean_squared_error(rf_season, svr_season_predict)\n",
    "    mape_svr_season = mean_absolute_percentage_error(rf_season, svr_season_predict)\n",
    "    mse_svr_resid = mean_squared_error(rf_resid, svr_resid_predict)\n",
    "    mape_svr_resid = mean_absolute_percentage_error(rf_resid, svr_resid_predict)\n",
    "    \n",
    "    print(\"trend svr\\t  MSE: \" + str(mse_svr_trend) + \"\\t MAPE: \"+ str(mape_svr_trend) + \"\\t sMAPE: \"+ str(smape_svr_trend))\n",
    "    print(\"season svr\\t  MSE: \" + str(mse_svr_season) + \"\\t MAPE: \"+ str(mape_svr_season) + \"\\t sMAPE: \"+ str(smape_svr_season))\n",
    "    print(\"resid svr\\t  MSE: \" + str(mse_svr_resid) + \"\\t MAPE: \"+ str(mape_svr_resid) + \"\\t sMAPE: \"+ str(smape_svr_resid))\n",
    "    \n",
    "    prueba = svr_trend_predict + svr_season_predict + svr_resid_predict\n",
    "    prueba_original = rf_trend + rf_season + rf_resid\n",
    "    print(\"Mape gral: \", mean_absolute_percentage_error(prueba, prueba_original))\n",
    "    print(\"sMape gral: \", smape(prueba, prueba_original))\n",
    "    print(\"Mse gral: \", mean_squared_error(prueba, prueba_original))\n",
    "    print(\"====================Done SVR====================\\n\")\n",
    "    return mape_svr_trend, mape_svr_season, mape_svr_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d36f91",
   "metadata": {},
   "source": [
    "## Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = None\n",
    "svr_trend_predict = None\n",
    "svr_season_predict = None\n",
    "svr_resid_predict = None\n",
    "rf_trend_predict = None\n",
    "rf_season_predict = None\n",
    "rf_resid_predict = None\n",
    "lstm_trend_predict = None\n",
    "lstm_season_predict = None\n",
    "lstm_resid_predict = None\n",
    "best_value = 0\n",
    "ponderacion = None\n",
    "\n",
    "\n",
    "def sintonizaEnsamble(): \n",
    "    #Datos de pronostico de los modelos   \n",
    "    ancho_hankel = 12   \n",
    "    global svr_trend_predict, svr_season_predict, svr_resid_predict\n",
    "    global rf_trend_predict, rf_season_predict, rf_resid_predict\n",
    "    global lstm_trend_predict, lstm_season_predict, lstm_resid_predict\n",
    "    \n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "    train_tren = pd.DataFrame(train_trend).to_numpy()\n",
    "    train_seaso = pd.DataFrame(train_season).to_numpy()\n",
    "    train_resi = pd.DataFrame(train_resid).to_numpy()\n",
    "    val_tren = pd.DataFrame(val_trend).to_numpy()\n",
    "    val_seaso = pd.DataFrame(val_season).to_numpy()\n",
    "    val_resi = pd.DataFrame(val_resid).to_numpy()\n",
    "    \n",
    "    val_tren = np.concatenate((train_tren,val_tren), axis=0)\n",
    "    val_seaso = np.concatenate((train_seaso,val_seaso), axis=0)\n",
    "    val_resi = np.concatenate((train_resi,val_resi), axis=0)\n",
    "    \n",
    "    trend = np.array(val_tren).reshape(-1,1)\n",
    "    season = np.array(val_seaso).reshape(-1,1)\n",
    "    resid = np.array(val_resi).reshape(-1,1)\n",
    "    #serie\n",
    "    global serie\n",
    "    serie = trend+season+resid\n",
    "    serie = np.delete(serie, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_tren)-ancho_hankel):\n",
    "        fila = val_tren[index:index+ancho_hankel]\n",
    "        rf_trend_char.append(fila)\n",
    "        index +=1\n",
    "    rf_trend_char = np.array(rf_trend_char)\n",
    "    rf_trend_char = np.reshape(rf_trend_char,(rf_trend_char.shape[0],rf_trend_char.shape[1]))\n",
    "    rf_trend = np.array(val_tren).reshape(-1,1)\n",
    "    rf_trend = np.delete(rf_trend, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_seaso)-ancho_hankel):\n",
    "        fila = val_seaso[index:index+ancho_hankel]\n",
    "        rf_season_char.append(fila)\n",
    "        index +=1\n",
    "    rf_season_char = np.array(rf_season_char)\n",
    "    rf_season_char = np.reshape(rf_season_char,(rf_season_char.shape[0],rf_season_char.shape[1]))\n",
    "    rf_season = np.array(val_seaso).reshape(-1,1)\n",
    "    rf_season = np.delete(rf_season, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_resi)-ancho_hankel):\n",
    "        fila = val_resi[index:index+ancho_hankel]\n",
    "        rf_resid_char.append(fila)\n",
    "        index +=1\n",
    "    rf_resid_char = np.array(rf_resid_char)\n",
    "    rf_resid_char = np.reshape(rf_resid_char,(rf_resid_char.shape[0],rf_resid_char.shape[1]))\n",
    "    rf_resid = np.array(val_resi).reshape(-1,1)\n",
    "    rf_resid = np.delete(rf_resid, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    \n",
    "    ####Evaluo para svr\n",
    "    svr_trend_predict = svr_trend_model.predict(rf_trend_char)\n",
    "    svr_season_predict = svr_season_model.predict(rf_season_char)\n",
    "    svr_resid_predict = svr_resid_model.predict(rf_resid_char)\n",
    "\n",
    "    ####Evaluo para Random Forest\n",
    "    rf_trend_predict = rf_trend_model.predict(rf_trend_char)\n",
    "    rf_season_predict = rf_season_model.predict(rf_season_char)\n",
    "    rf_resid_predict = rf_resid_model.predict(rf_resid_char)\n",
    "    \n",
    "    ####Evaluo para LSTM\n",
    "    lstm_trend_predict = lstm_model_trend.predict(rf_trend_char, verbose = 0)\n",
    "    lstm_season_predict = lstm_model_season.predict(rf_season_char, verbose = 0) \n",
    "    lstm_resid_predict = lstm_model_resid.predict(rf_resid_char, verbose = 0) \n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "    \n",
    "    ga_instance = pygad.GA(num_generations=10000,\n",
    "                       num_parents_mating=250, #Padres\n",
    "                       fitness_func=ensamble_fitness,###################\n",
    "                       sol_per_pop=500, #tamaño de la poblacion\n",
    "                       num_genes=9,########################\n",
    "                       mutation_type=\"adaptive\",\n",
    "                       mutation_probability=(0.9,0.2),\n",
    "                       init_range_low=0,\n",
    "                       keep_elitism=50,\n",
    "                       keep_parents=50,\n",
    "                       crossover_type=\"scattered\",\n",
    "                       allow_duplicate_genes=False,\n",
    "                       parent_selection_type=\"rws\",\n",
    "                       gene_space = [range(-100,100),range(-100,100),range(-100,100),range(-100,100),range(-100,100),range(-100,100),range(-100,100),range(-100,100),range(-100,100)],\n",
    "                       stop_criteria=[\"saturate_100\"],\n",
    "                       gene_type=int)\n",
    "    print(\"====================Start Genetic====================\")\n",
    "    start = time.time()\n",
    "    ga_instance.run()\n",
    "    ga_instance.plot_fitness()\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Go!')\n",
    "    print(\"Time GA: \" + str(round(end - start,1)) + \" seconds\")\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    print(\"Prueba ensamble entrenamiento-validación\")\n",
    "    print(\"Mejor Solución encontrada : {solution}\".format(solution=solution))\n",
    "    print(\"Mejor MSE encontrado: \" + str(1.0/best_value))\n",
    "    global ponderacion\n",
    "    ponderacion = solution\n",
    "    build_ensamble(solution, True)\n",
    "    print(\"====================Done Genetic====================\\n\")\n",
    "    return solution\n",
    "\n",
    "def build_ensamble(solution, plot):\n",
    "    svr_trend= solution[0]\n",
    "    svr_season= solution[1]\n",
    "    svr_resid = solution[2]\n",
    "    rf_trend = solution[3]\n",
    "    rf_season = solution[4]\n",
    "    rf_resid = solution[5]\n",
    "    lstm_trend = solution[6]\n",
    "    lstm_season = solution[7]\n",
    "    lstm_resid = solution[8]\n",
    "    #SVR\n",
    "    svr_trend_p = svr_trend_predict * (svr_trend/100)\n",
    "    svr_season_p = svr_season_predict * (svr_season/100)\n",
    "    svr_resid_p = svr_resid_predict * (svr_resid/100)\n",
    "    #RFR\n",
    "    rf_trend_p = rf_trend_predict * (rf_trend/100)\n",
    "    rf_season_p = rf_season_predict * (rf_season/100)\n",
    "    rf_resid_p = rf_resid_predict * (rf_resid/100)\n",
    "    #LSTM\n",
    "    lstm_trend_p = lstm_trend_predict * (lstm_trend/100)\n",
    "    lstm_season_p = lstm_season_predict * (lstm_season/100)\n",
    "    lstm_resid_p = lstm_resid_predict * (lstm_resid/100)\n",
    "    \n",
    "    lstm_trend_p = np.array(lstm_trend_p).reshape(lstm_trend_p.shape[0])\n",
    "    lstm_season_p = np.array(lstm_season_p).reshape(lstm_season_p.shape[0])\n",
    "    lstm_resid_p = np.array(lstm_resid_p).reshape(lstm_resid_p.shape[0])\n",
    "    \n",
    "    construccion = svr_trend_p + svr_season_p + svr_resid_p\n",
    "    construccion += rf_trend_p + rf_season_p + rf_resid_p\n",
    "    construccion += lstm_trend_p + lstm_season_p + lstm_resid_p\n",
    "    \n",
    "    mse = mean_squared_error(serie, construccion)\n",
    "    mape = mean_absolute_percentage_error(serie, construccion)\n",
    "    smape_v = smape(serie, construccion)\n",
    "    if plot:\n",
    "        print(\"Mejor MAPE encontrado: \", mape)\n",
    "        print(\"Mejor sMAPE encontrado: \", smape_v)\n",
    "        print(\"Mejor MSE encontrado: \", mse)\n",
    "        plt.figure(figsize=(20, 8))\n",
    "        plt.plot(construccion, color = \"green\")\n",
    "        plt.plot(serie, color = \"pink\")\n",
    "        plt.plot()\n",
    "        plt.show()\n",
    "    return mape\n",
    "\n",
    "def ensamble_fitness(ga_instance,solution, solution_idx): #Función que mide el rmse de cada variante de red neuronal\n",
    "    fitness = build_ensamble(solution, False)\n",
    "    #print(\"original -> \"+ str(fitness) + \" Adec: \"+str(1.0/fitness))\n",
    "    fitness = 1.0/(fitness)\n",
    "    global best_value\n",
    "    if best_value < fitness:\n",
    "        best_value = fitness\n",
    "        #print(best_value, end='...')\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8591ee",
   "metadata": {},
   "source": [
    "##  Calculo Salida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59584fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_output():\n",
    "    svr_trend= ponderacion[0]\n",
    "    svr_season= ponderacion[1]\n",
    "    svr_resid = ponderacion[2]\n",
    "    rf_trend = ponderacion[3]\n",
    "    rf_season = ponderacion[4]\n",
    "    rf_resid = ponderacion[5]\n",
    "    lstm_trend = ponderacion[6]\n",
    "    lstm_season = ponderacion[7]\n",
    "    lstm_resid = ponderacion[8]\n",
    "    \n",
    "    #Datos de pronostico de los modelos   \n",
    "    ancho_hankel = 12   \n",
    "    global svr_trend_predict, svr_season_predict, svr_resid_predict\n",
    "    global rf_trend_predict, rf_season_predict, rf_resid_predict\n",
    "    global lstm_trend_predict, lstm_season_predict, lstm_resid_predict\n",
    "    \n",
    "    \n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "    val_tren = pd.DataFrame(test_trend).to_numpy() \n",
    "    val_seaso = pd.DataFrame(test_season).to_numpy()\n",
    "    val_resi = pd.DataFrame(test_resid).to_numpy()\n",
    "    \n",
    "    \n",
    "    trend = np.array(val_tren).reshape(-1,1)\n",
    "    season = np.array(val_seaso).reshape(-1,1)\n",
    "    resid = np.array(val_resi).reshape(-1,1)\n",
    "    #serie\n",
    "    global serie\n",
    "    serie = trend+season+resid\n",
    "    serie = np.delete(serie, range(1,ancho_hankel+1))\n",
    "    #########################################################################################\n",
    "    #Hankel Trend\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_trend_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_tren)-ancho_hankel):\n",
    "        fila = val_tren[index:index+ancho_hankel]\n",
    "        rf_trend_char.append(fila)\n",
    "        index +=1\n",
    "    rf_trend_char = np.array(rf_trend_char)\n",
    "    rf_trend_char = np.reshape(rf_trend_char,(rf_trend_char.shape[0],rf_trend_char.shape[1]))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Season\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_season_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_seaso)-ancho_hankel):\n",
    "        fila = val_seaso[index:index+ancho_hankel]\n",
    "        rf_season_char.append(fila)\n",
    "        index +=1\n",
    "    rf_season_char = np.array(rf_season_char)\n",
    "    rf_season_char = np.reshape(rf_season_char,(rf_season_char.shape[0],rf_season_char.shape[1]))\n",
    "    #########################################################################################\n",
    "    \n",
    "    #########################################################################################\n",
    "    #Hankel Resid\n",
    "    ancho_hankel = 12   #Un periodo estacional\n",
    "    rf_resid_char = []\n",
    "    index = 0\n",
    "    for i in range(len(val_resi)-ancho_hankel):\n",
    "        fila = val_resi[index:index+ancho_hankel]\n",
    "        rf_resid_char.append(fila)\n",
    "        index +=1\n",
    "    rf_resid_char = np.array(rf_resid_char)\n",
    "    rf_resid_char = np.reshape(rf_resid_char,(rf_resid_char.shape[0],rf_resid_char.shape[1]))\n",
    "    #########################################################################################\n",
    "    \n",
    "    ####Evaluo para svr\n",
    "    svr_trend_predict = svr_trend_model.predict(rf_trend_char)\n",
    "    svr_season_predict = svr_season_model.predict(rf_season_char)\n",
    "    svr_resid_predict = svr_resid_model.predict(rf_resid_char)\n",
    "\n",
    "    ####Evaluo para Random Forest\n",
    "    rf_trend_predict = rf_trend_model.predict(rf_trend_char)\n",
    "    rf_season_predict = rf_season_model.predict(rf_season_char)\n",
    "    rf_resid_predict = rf_resid_model.predict(rf_resid_char)\n",
    "    ####Evaluo para LSTM\n",
    "    lstm_trend_predict = lstm_model_trend.predict(rf_trend_char, verbose = 0)\n",
    "    lstm_season_predict = lstm_model_season.predict(rf_season_char, verbose = 0) \n",
    "    lstm_resid_predict = lstm_model_resid.predict(rf_resid_char, verbose = 0) \n",
    "    \n",
    "    \n",
    "\n",
    "    #SVR\n",
    "    svr_trend_p = svr_trend_predict * (svr_trend/100)\n",
    "    svr_season_p = svr_season_predict * (svr_season/100)\n",
    "    svr_resid_p = svr_resid_predict * (svr_resid/100)\n",
    "    #RFR\n",
    "    rf_trend_p = rf_trend_predict * (rf_trend/100)\n",
    "    rf_season_p = rf_season_predict * (rf_season/100)\n",
    "    rf_resid_p = rf_resid_predict * (rf_resid/100)\n",
    "    #LSTM\n",
    "    lstm_trend_p = lstm_trend_predict * (lstm_trend/100)\n",
    "    lstm_season_p = lstm_season_predict * (lstm_season/100)\n",
    "    lstm_resid_p = lstm_resid_predict * (lstm_resid/100)\n",
    "    \n",
    "    lstm_trend_p = np.array(lstm_trend_p).reshape(lstm_trend_p.shape[0])\n",
    "    lstm_season_p = np.array(lstm_season_p).reshape(lstm_season_p.shape[0])\n",
    "    lstm_resid_p = np.array(lstm_resid_p).reshape(lstm_resid_p.shape[0])\n",
    "    \n",
    "    construccion = svr_trend_p + svr_season_p + svr_resid_p\n",
    "    construccion += rf_trend_p + rf_season_p + rf_resid_p\n",
    "    construccion += lstm_trend_p + lstm_season_p + lstm_resid_p\n",
    "    \n",
    "    mse = mean_squared_error(serie, construccion)\n",
    "    smape_v = smape(serie, construccion)\n",
    "    mape = mean_absolute_percentage_error(serie, construccion)\n",
    "    global best_mse, best_mape, best_smape\n",
    "    best_mse += mse\n",
    "    best_mape += mape\n",
    "    best_smape += smape_v\n",
    "    print(\"================================================================================================\")\n",
    "    print(\"===========================     PRONOSTICO SET PRUEBA FINAL     ================================\")\n",
    "    print(\"================================================================================================\")\n",
    "    print(\"MAPE: \", mape)\n",
    "    print(\"sMAPE: \", smape_v)\n",
    "    print(\"MSE: \", mse)\n",
    "    print(\"RMSE: \", (mse**0.5))\n",
    "    print(\"================================================================================================\")\n",
    "    print(\"================================================================================================\\n\")\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(construccion, color = \"orange\")\n",
    "    plt.plot(serie, color = \"gray\")\n",
    "    plt.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f95a41",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8a6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "mse_rf_trend = None\n",
    "mse_rf_season = None\n",
    "mse_rf_resid = None\n",
    "mse_svr_trend = None\n",
    "mse_svr_season = None\n",
    "mse_svr_resid = None\n",
    "mse_lstm_trend = None\n",
    "mse_lstm_season = None\n",
    "mse_lstm_resid = None\n",
    "\n",
    " \n",
    "def ThreadRandomForest():\n",
    "    global mse_rf_trend, mse_rf_season, mse_rf_resid\n",
    "    mse_rf_trend, mse_rf_season, mse_rf_resid = randomForestTrain()\n",
    "    \n",
    "def ThreadLSTM():\n",
    "    global mse_lstm_trend, mse_lstm_season, mse_lstm_resid\n",
    "    mse_lstm_trend, mse_lstm_season, mse_lstm_resid = lstmTrain()\n",
    "    \n",
    "def ThreadSVR():\n",
    "    global mse_svr_trend, mse_svr_season, mse_svr_resid\n",
    "    mse_svr_trend, mse_svr_season, mse_svr_resid = SVRTrain()\n",
    "\n",
    "\n",
    "cantidad_corridas = 30\n",
    "print(\"Incia ejecución general\")\n",
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "best_mse = 0\n",
    "best_mape = 0\n",
    "best_smape = 0\n",
    "for i in range(cantidad_corridas):\n",
    "    print(\"\\nInicia ejecución \", (i+1))\n",
    "    start = time.time()\n",
    "    #mse_rf_trend, mse_rf_season, mse_rf_resid = randomForestTrain()\n",
    "    #mse_svr_trend, mse_svr_season, mse_svr_resid = SVRTrain()\n",
    "    t1 = threading.Thread(target=ThreadRandomForest)\n",
    "    t2 = threading.Thread(target=ThreadSVR)\n",
    "    t3 = threading.Thread(target=ThreadLSTM)\n",
    " \n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t3.start()\n",
    "    \n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    t3.join()\n",
    "\n",
    "\n",
    "    #######################################################################\n",
    " \n",
    "    # both threads completely executed\n",
    "    print(\"Done!\")\n",
    "    end = time.time()\n",
    "    print(\"Time process: \" + str(round(end - start,1)) + \" seconds\")\n",
    "    sintonizaEnsamble()\n",
    "    build_output()\n",
    "    print(\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\")\n",
    "    tf.keras.backend.clear_session()\n",
    "global best_mse, best_mape, best_smape\n",
    "best_mse = best_mse/cantidad_corridas\n",
    "best_mape = best_mape/cantidad_corridas\n",
    "best_smape = best_smape/cantidad_corridas\n",
    "print(\"MSE total:  \", best_mse)\n",
    "print(\"MAPE total: \", best_mape)\n",
    "print(\"sMAPE total: \", best_smape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
